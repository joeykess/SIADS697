{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fced38c-3bfc-4138-9cda-70b1914d452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from threading import Event\n",
    "import DatastreamDSWS as DSWS\n",
    "import eikon as ek\n",
    "import pandas as pd\n",
    "from eikon.tools import get_date_from_today\n",
    "import config\n",
    "ek.set_app_key(config.ek_key())\n",
    "ds = DSWS.Datastream(username=config.username_ds(), password=config.pw_ds())\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0f0cc0-fb5d-46f3-95dc-79ba0b49d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:poRter!5067@databasesec.cvhiyxfodl3e.us-east-2.rds.amazonaws.com:5432/697_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a978af1-3cf7-48c2-a04b-7d2316d32076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spy_stocks_pkl():\n",
    "    \"\"\"This function imports the Symbols (RICS) for all stocks in the SPDR SP 500 ETF do not run w/o a\n",
    "    subscription to refinitive. \"\"\"\n",
    "    date = datetime.now().date().strftime('%Y-%m-%d')\n",
    "    hold = ek.get_data('SPY', fields=[ek.TR_Field('TR.ETPConstituentRIC', params={'SDate': date})])[0]\n",
    "    hold = hold[hold['Constituent RIC'] != 'GOOG.OQ']\n",
    "    rics = [x for x in hold['Constituent RIC']]\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rics, f)\n",
    "    return\n",
    "get_spy_stocks_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d877fc-c4a1-467b-ae1c-385202516dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    \"\"\"Helper function that assist in managing batch sizes\"\"\"\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3dcea2-61f9-4655-a4cc-c8f42e751cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_volume_features():\n",
    "    \"\"\"Retrives daily trading volume data do not use without a subscription to Eikon\"\"\"\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    vol_df = pd.DataFrame()\n",
    "    timer = Event()\n",
    "    for x in batch(rics, 2):\n",
    "        try:\n",
    "            q_1 = ek.get_timeseries(x, fields=\"VOLUME\", start_date=get_date_from_today(1095), interval='daily')\n",
    "            vol_df = vol_df.join(q_1, how='outer')\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            q_1 = ek.get_timeseries(x, fields=\"VOLUME\", start_date=get_date_from_today(1095), interval='daily')\n",
    "            vol_df = vol_df.join(q_1, how='outer')\n",
    "        if len(vol_df.columns)%50==0:\n",
    "            print(len(vol_df.columns))\n",
    "    vol_df = vol_df.dropna(axis=1)\n",
    "    vol_12m = vol_df.rolling(252).mean().dropna(axis=0, how='all')\n",
    "    vol_12 = vol_12m.rename(columns={i: '{}_12m_volume'.format(i) for i in vol_12m.columns})\n",
    "    vol_3m = vol_df.rolling(63).mean().dropna(axis=0, how='all')\n",
    "    vol_3 = vol_3m.rename(columns={i: '{}_3m_volume'.format(i) for i in vol_3m.columns})\n",
    "    vol_6m = vol_df.rolling(126).mean().dropna(axis=0, how='all')\n",
    "    vol_6 = vol_6m.rename(columns={i: '{}_6m_volume'.format(i) for i in vol_6m.columns})\n",
    "    dfs = [vol_12, vol_6, vol_3]\n",
    "    table_names = [\"vol_12\", \"vol_6\", \"vol_3\"]\n",
    "    for i in range(0, len(dfs)):\n",
    "        dfs[i].reset_index().to_sql('{}'.format(table_names[i]), con = engine, if_exists = 'replace', index = False)\n",
    "        conn = engine.raw_connection()\n",
    "        cur = conn.cursor()\n",
    "        output = io.StringIO()\n",
    "        dfs[i].to_csv(\"assets/models/jeff_multi_factor/{}_df.csv\".format(table_names[i]), sep='\\t', header=False, index=False)\n",
    "        output.seek(0)\n",
    "        contents = output.getvalue()\n",
    "        cur.copy_from(output, table_names[i], null=\"\") # null values become ''\n",
    "        conn.commit()\n",
    "        os.remove(\"assets/models/jeff_multi_factor/{}_df.csv\".format(table_names[i]))\n",
    "    \n",
    "    print('Done!')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68a32c6-00cd-4a6c-822b-f6b80991041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "create_volume_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0cf3dc-9859-41d5-864c-1cbfbf27a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_income_stat_dat():\n",
    "    \"\"\"\"Retrieves income statement data for each S&P 500 company do not use without subscription to Eikon\"\"\"\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    is_dat = pd.DataFrame()\n",
    "    timer = Event()\n",
    "    for i in batch(rics, 40):\n",
    "        try:\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.EPSBasicInclExordItemsComTot\",\n",
    "                                       \"TR.F.EPSBasicExclExordItemsComTot\", \"TR.F.EPSDilExclExordItemsComTot\",\n",
    "                                       \"TR.F.EPSBasicInclExOrdComTotPoPDiff\", \"TR.F.EBIT\", \"TR.F.EBITDA\",\n",
    "                                       \"TR.F.TotRevenue\", \"TR.F.IncAvailToComShr\"],\n",
    "                            parameters={\"Period\": \"LTM\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            is_dat = pd.concat([is_dat, t])\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.EPSBasicInclExordItemsComTot\",\n",
    "                                       \"TR.F.EPSBasicExclExordItemsComTot\", \"TR.F.EPSDilExclExordItemsComTot\",\n",
    "                                       \"TR.F.EPSBasicInclExOrdComTotPoPDiff\", \"TR.F.EBIT\", \"TR.F.EBITDA\",\n",
    "                                       \"TR.F.TotRevenue\", \"TR.F.IncAvailToComShr\"],\n",
    "                            parameters={\"Period\": \"LTM\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            is_dat = pd.concat([is_dat, t])\n",
    "    is_dat.to_sql(\"inc_stat\", con = engine, if_exists = 'replace', index = False)\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    is_dat.to_csv('assets/models/jeff_multi_factor/income_stat_dat.csv', sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, \"inc_stat\")\n",
    "    conn.commit()\n",
    "    os.remove(\"assets/models/jeff_multi_factor/income_stat_dat.csv\")    \n",
    "    print(\"done\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57b5b24-daf5-4b3e-9ca7-e9bb99b2dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bal_sheet_dat():\n",
    "    \"\"\"Retrieves balance sheet data for each S&P 500 company do not use without a subscription to Eikon\"\"\"\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    bs_dat = pd.DataFrame()\n",
    "    timer = Event()\n",
    "    for i in batch(rics, 40):\n",
    "        try:\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.TotAssets\", \"TR.F.OthAssetsTot\",\n",
    "                                       \"TR.F.CashSTInvstTot\", \"TR.F.TotShHoldEq\", \"TR.F.TangTotEq\", \"TR.F.DebtTot\",\n",
    "                                       \"TR.F.TotLTCap\", \"TR.F.IntangTotNet\", \"TR.F.BookValuePerShr\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            bs_dat = pd.concat([bs_dat, t])\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.TotAssets\", \"TR.F.OthAssetsTot\",\n",
    "                                       \"TR.F.CashSTInvstTot\", \"TR.F.TotShHoldEq\", \"TR.F.TangTotEq\", \"TR.F.DebtTot\",\n",
    "                                       \"TR.F.TotLTCap\", \"TR.F.IntangTotNet\", \"TR.F.BookValuePerShr\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            bs_dat = pd.concat([bs_dat, t])\n",
    "    bs_dat.to_sql(\"bal_sht\", con = engine, if_exists = 'replace', index = False)\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    bs_dat.to_csv('assets/models/jeff_multi_factor/bal_sht_dat.csv', sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, \"bal_sht\")\n",
    "    conn.commit()\n",
    "    os.remove('assets/models/jeff_multi_factor/bal_sht_dat.csv')    \n",
    "    print(\"done\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86a5676-ba26-41a2-b98b-9929a715c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_dat():\n",
    "    \"\"\"\"Retrieves cashflow data for all S&P 500 Companies, do not use without subscriotion to Eikon\"\"\"\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    cf_dat = pd.DataFrame()\n",
    "    timer = Event()\n",
    "    for i in batch(rics, 40):\n",
    "        try:\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.NetCashFlowOp\", \"TR.F.CAPEXTot\",\n",
    "                                       \"TR.F.NetCFOpPerShr\", \"TR.F.FreeCashFlowToEq\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            cf_dat = pd.concat([cf_dat, t])\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.NetCashFlowOp\", \"TR.F.CAPEXTot\",\n",
    "                                       \"TR.F.NetCFOpPerShr\", \"TR.F.FreeCashFlowToEq\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            cf_dat = pd.concat([cf_dat, t])\n",
    "    cf_dat.to_sql(\"cf_stat\", con = engine, if_exists = 'replace', index = False)\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    cf_dat.to_csv('assets/models/jeff_multi_factor/cf_dat.csv', sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, \"cf_stat\")\n",
    "    conn.commit()\n",
    "    os.remove(\"assets/models/jeff_multi_factor/cf_dat.csv\")    \n",
    "    print(\"done\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634500a6-3004-424a-ab35-cb86450b9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qual_dat():\n",
    "    \"\"\"Retrieves quality and profitability data for all S&P 500 companies - do not use without subscription to Eikon\"\"\"\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    ql_dat = pd.DataFrame()\n",
    "    timer = Event()\n",
    "    for i in batch(rics, 40):\n",
    "        try:\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.ReturnAvgComEqPctTTM\",\n",
    "                                       \"TR.F.ReturnAvgTotAssetsPctTTM\", \"TR.F.ReturnAvgTotLTCapPctTTM\",\n",
    "                                       \"TR.F.ReturnInvstCapPctTTM\", \"TR.F.TotDebtPctofTotEq\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            ql_dat = pd.concat([ql_dat, t])\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            t = ek.get_data(i, fields=[\"TR.F.OriginalAnnouncementDate\", \"TR.F.ReturnAvgComEqPctTTM\",\n",
    "                                       \"TR.F.ReturnAvgTotAssetsPctTTM\", \"TR.F.ReturnAvgTotLTCapPctTTM\",\n",
    "                                       \"TR.F.ReturnInvstCapPctTTM\", \"TR.F.TotDebtPctofTotEq\"],\n",
    "                            parameters={\"Period\": \"FQ0\", \"Frq\": \"FQ\", \"SDate\": 0, \"Edate\": -7})[0]\n",
    "            ql_dat = pd.concat([ql_dat, t])\n",
    "    ql_dat.to_sql(\"qual_dat\", con = engine, if_exists = 'replace', index = False)\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    ql_dat.to_csv('assets/models/jeff_multi_factor/qual_dat.csv', sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, \"qual_dat\")\n",
    "    conn.commit()\n",
    "    os.remove('assets/models/jeff_multi_factor/qual_dat.csv')    \n",
    "    print(\"done\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022636ed-a84c-4e0a-8075-68978e6841b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mv():\n",
    "    \"\"\"retrieves market cap data for all S&P 500 companies do not use without a subscription to datastream \"\"\"\n",
    "    timer = Event()\n",
    "    with open(\"assets/models/jeff_multi_factor/spy_rics.pkl\", \"rb\") as f:\n",
    "        rics = pickle.load(f)\n",
    "    df = pd.DataFrame()\n",
    "    for i in batch(rics, 2):\n",
    "        get = '<{}>,<{}>'.format(i[0], i[1])\n",
    "        try:\n",
    "            data = ds.get_data(tickers=get, fields=['MV'], start=\"2017-12-31\", freq='D')\n",
    "            df = df.join(data, how='outer')\n",
    "            if len(df.columns)%50 ==0:\n",
    "                print(len(df.columns))\n",
    "        except:\n",
    "            timer.wait(10)\n",
    "            data = ds.get_data(tickers=get, fields=['MV'], start=\"2017-12-31\", freq='D')\n",
    "            df = df.join(data, how='outer')\n",
    "            if len(df.columns)%50 ==0:\n",
    "                print(len(df.columns))\n",
    "    df = df.reset_index()\n",
    "    df.to_sql(\"mkt_cap\", con = engine, if_exists = 'replace', index = False)\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    df.to_csv('assets/models/jeff_multi_factor/mkt_cap.csv', sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, \"mkt_cap\")\n",
    "    conn.commit()\n",
    "    os.remove('assets/models/jeff_multi_factor/mkt_cap.csv')    \n",
    "    print(\"done\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293d5fc-32ea-4904-8d64-8864b9759137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\anaconda3\\envs\\capstone\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:648: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "get_mv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a5021-8192-42f4-9323-68cfc476ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
