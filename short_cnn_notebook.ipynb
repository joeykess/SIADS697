{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import tensorflow\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras import metrics\n",
    "from keras import callbacks\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_stock_info():\n",
    "    \"\"\"\n",
    "    This function outputs all csv files to /assets/historical-symbols/ directory as individual CSV files per stocks\n",
    "    Will be choosing 10 stocks that make up the top of the S&P500\n",
    "    \"\"\"\n",
    "    symbol_list = ['NVDA', 'AMD', 'JPM', 'JNJ', 'MRNA', 'F', 'TSLA', 'MSFT', 'BAC', 'BABA', 'SPY', 'QQQ']\n",
    "    # ones that work with alpha vantage (no nasdaq)\n",
    "    # chosen for high volume and availability on alpha vantage\n",
    "    av_api_key = os.getenv('ALPHAVANTAGE_API_KEY')\n",
    "    slices = ['year{}month{}'.format(a, b) for a in range(1, 3) for b in range(1, 13)]\n",
    "    for ticker in tqdm(symbol_list):\n",
    "        ticker_df = pd.DataFrame()\n",
    "        for slice in slices:\n",
    "            # each request takes approximately 3 seconds\n",
    "            csv_url = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=' \\\n",
    "                      '{}&interval=5min&slice={}&apikey={}'.format(ticker, slice, av_api_key)\n",
    "            new_df = pd.read_csv(csv_url, header=0)\n",
    "            ticker_df = ticker_df.append(new_df)\n",
    "        ticker_df.to_csv('assets/short_term_symbols/{}.csv'.format(ticker))\n",
    "        # sleeps 15 seconds just to make sure no timeout is incurred\n",
    "        time.sleep(15)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91165056",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cwd = os.getcwd()\n",
    "    path = os.path.join(cwd, 'assets/short_term_symbols')\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    get_short_stock_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_bands(data, sma, window):\n",
    "    std = data.rolling(window=window).std()\n",
    "    upper_bb = sma + std * 2\n",
    "    lower_bb = sma - std * 2\n",
    "    return upper_bb, lower_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_candles(plot_df, folder, file):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    mpf.plot(plot_df, type='candlestick', style='charles', ax=ax)\n",
    "    plot_df.reset_index().plot(kind='line', y='upper_bb', color='blue', lw=3, alpha=0.75, ax=ax, legend=None)\n",
    "    plot_df.reset_index().plot(kind='line', y='lower_bb', color='orange', lw=3, alpha=0.75, ax=ax, legend=None)\n",
    "    plot_df.reset_index().plot(kind='line', y='ema12', color='black', lw=3, alpha=0.75, ax=ax, legend=None)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.axis('off')\n",
    "    save_spot = f'assets/cnn_images_5m/{folder}/'\n",
    "    if not os.path.exists(save_spot):\n",
    "        os.makedirs(save_spot)\n",
    "    plt.savefig(f'{save_spot}/{file}.png', dpi=50, bbox_inches='tight')\n",
    "    try:\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a110c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candle_creator(ticker, num_index):\n",
    "    df = pd.read_csv(f'assets/short_term_symbols/{ticker}.csv').drop(columns=['Unnamed: 0'])\n",
    "    df = df.reindex(index=df.index[::-1])\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.set_index(df['time']).drop(columns=['time'])\n",
    "    df = df.resample('5min').first()\n",
    "    df[['open', 'high', 'low', 'close']] = df[['open', 'high', 'low', 'close']].ffill()\n",
    "    df['volume'] = df['volume'].fillna(0)\n",
    "    df['MA12'] = df['close'].rolling(window=12).mean()\n",
    "    df['upper_bb'], df['lower_bb'] = bollinger_bands(df['close'], df['MA12'], 12)\n",
    "    df['ema12'] = df['close'].ewm(span=12).mean()\n",
    "    df = df[(df.index < '2020-07-19')]\n",
    "    df = df.iloc[11:]\n",
    "    # doing every 30m intervals\n",
    "    for start in range(0, df.shape[0], 6):\n",
    "        data = df.iloc[start:start + num_index].copy()\n",
    "        # when a quarter the data is filled in skip for training purpose\n",
    "        last_point = data[['open', 'high', 'low', 'close']].iloc[0].mean()\n",
    "        next_points = [last_point]\n",
    "        # checks if next point has volume then creates chart\n",
    "        next_row = df.iloc[start+1]\n",
    "        same_day = next_row.name.hour > 4\n",
    "        if next_row['volume'] > 0.0 and same_day:\n",
    "            next_points.append(next_row[['open', 'high', 'low', 'close']].mean())\n",
    "            if next_points[1] > next_points[0]:\n",
    "                folder = 'buy'\n",
    "            else:\n",
    "                folder = 'hold'\n",
    "\n",
    "            file = ticker + '_' + str(start)\n",
    "            if 0.0 in data['volume'].value_counts():\n",
    "                if data['volume'].value_counts()[0.0] <= 4:\n",
    "                    create_candles(data, folder, file)\n",
    "            else:\n",
    "                create_candles(data, folder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79215846",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = ['NVDA', 'AMD', 'JPM', 'JNJ', 'MRNA', 'F', 'TSLA', 'MSFT', 'BAC', 'BABA', 'SPY', 'QQQ']\n",
    "if not os.path.exists('assets/cnn_images_5m'):\n",
    "    os.makedirs('assets/cnn_images_5m')\n",
    "for symbol in tqdm(symbol_list):\n",
    "    try:\n",
    "        candle_creator(ticker=symbol, num_index=12)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32343652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially this was done with 27 classes (x_x_x denoting changes within every 5 minutes for 15 minutes) \n",
    "# but it was very innacurate so 2 classes were used - buy or not buy\n",
    "# to classify the models\n",
    "plt.imread('assets/cnn_images_5m/buy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dc3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_model(width, height, num_samples, needs_split=False):\n",
    "    \"\"\"\n",
    "    This trains a cnn model and outputs the model to the specified location below\n",
    "    :param width: width of image\n",
    "    :param height: height of image\n",
    "    :param num_samples: total number of samples that are being split\n",
    "    :param needs_split: if the samples are split into the output folder or not\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    if needs_split:\n",
    "        splitfolders.ratio(\"assets/cnn_images_5m/\", output=\"assets/cnn_images_5m/output\",\n",
    "                           seed=0, ratio=(0.8, 0.1, 0.1), group_prefix=None)\n",
    "\n",
    "    model_metrics = ['accuracy', metrics.BinaryCrossentropy(), metrics.Precision(),\n",
    "                     metrics.Recall(), metrics.BinaryAccuracy()]\n",
    "    img_width, img_height = width, height\n",
    "    train_data_dir = 'assets/cnn_images_5m/output/train'\n",
    "    val_data_dir = 'assets/cnn_images_5m/output/val'\n",
    "    test_data_dir = 'assets/cnn_images_5m/output/test'\n",
    "    epochs = 75\n",
    "    validation_steps = 300\n",
    "    batch_size = 32\n",
    "    classes_num = 2\n",
    "    nb_filters1 = 16\n",
    "    nb_filters2 = 32\n",
    "    conv1_size = 4\n",
    "    conv2_size = 2\n",
    "    pool_size = 2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, input_shape=(img_width, img_height, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "    model.add(Convolution2D(nb_filters2, conv2_size, conv2_size))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes_num, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=model_metrics)\n",
    "\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    # buy is 0, hold is 1\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    log_dir = './tf-log/'\n",
    "    tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "    cbks = [tb_cb]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=256,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=cbks,\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "    target_dir = './models/'\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    model.save(f'assets/models/joey_cnn_intraday/cnn_model_5m_{epochs}epochs_{classes_num}classes.h5')\n",
    "    model.save_weights(f'assets/models/joey_cnn_intraday/cnn_weights_5m_{epochs}epochs_{classes_num}classes.h5')\n",
    "\n",
    "    with open(f'assets/models/joey_cnn_intraday/history_5m_{epochs}epochs_{classes_num}classes.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    print('binary_accuracy', history.history['val_binary_accuracy'])\n",
    "    print('precision', history.history['val_precision'])\n",
    "    print('recall', history.history['val_recall'])\n",
    "\n",
    "    # Calculate execution time\n",
    "    end = time.time()\n",
    "    dur = end - start\n",
    "\n",
    "    if dur < 60:\n",
    "        print(\"Execution Time:\", dur, \"seconds\")\n",
    "    elif 60 < dur < 3600:\n",
    "        dur = dur / 60\n",
    "        print(\"Execution Time:\", dur, \"minutes\")\n",
    "    else:\n",
    "        dur = dur / (60 * 60)\n",
    "        print(\"Execution Time:\", dur, \"hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8789d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_split = True\n",
    "if os.path.exists('assets/cnn_images_5m/output'):\n",
    "    needs_split = False\n",
    "train_cnn_model(width=203, height=202, num_samples=64947, needs_split=needs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b31b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d402a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
